import pandas as pd
import numpy as np
import tushare as ts
import sqlite3
import time
from datetime import datetime, timedelta
from config import TS_TOKEN, INDEX_MAP, DB_PATH

# 1. è®¾ç½® Tushare
ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# 2. è¾…åŠ©å‡½æ•°ï¼šè·å–åŒºé—´
def get_quarters(start_date, end_date):
    """å°†å¤§æ—¶é—´æ®µåˆ‡å‰²ä¸ºå­£åº¦åŒºé—´ [(start, end), ...]"""
    quarters = pd.date_range(start=start_date, end=end_date, freq='Q') # Quarter End
    intervals = []
    
    # è½¬æ¢é€»è¾‘
    curr = datetime.strptime(start_date, '%Y%m%d')
    for q_end in quarters:
        q_end_str = q_end.strftime('%Y%m%d')
        if q_end_str > end_date:
            break
        intervals.append((curr.strftime('%Y%m%d'), q_end_str))
        curr = q_end + timedelta(days=1)
    
    # åŠ ä¸Šæœ€åä¸€æ®µ (å¦‚æœ end_date ä¸æ˜¯å­£åº¦æœ«)
    last_start = curr.strftime('%Y%m%d')
    if last_start <= end_date:
        intervals.append((last_start, end_date))
        
    return intervals

def get_constituents_safe(index_code, date_str):
    """
    æ™ºèƒ½è·å–æˆåˆ†è‚¡ï¼š
    - ä¸Šè¯æŒ‡æ•°(000001.SH): è·å–å½“æ—¥ä¸Šäº¤æ‰€æ‰€æœ‰ä¸Šå¸‚è‚¡ç¥¨
    - å…¶ä»–æŒ‡æ•°: æŸ¥è¯¢ index_weight
    """
    try:
        # === ç‰¹æ®Šå¤„ç†ï¼šä¸Šè¯æŒ‡æ•° ===
        if index_code == '000001.SH':
            # è·å–è¯¥æ—¥æœŸä»åœ¨ä¸Šå¸‚çš„ SSE è‚¡ç¥¨
            # list_status='L' (ä¸Šå¸‚), exchange='SSE'
            df = pro.stock_basic(exchange='SSE', list_status='L', fields='ts_code,list_date,delist_date')
            # ç­›é€‰ï¼šä¸Šå¸‚æ—¥æœŸ <= date_str
            df = df[df['list_date'] <= date_str]
            return df['ts_code'].tolist()
        
        # === å¸¸è§„æŒ‡æ•°ï¼šæ²ªæ·±300/ä¸­è¯500/åˆ›ä¸šæ¿ç­‰ ===
        # æ‰¾æœ€è¿‘çš„ä¸€ä¸ªæœˆå†…çš„æƒé‡æ•°æ®
        start_dt = (datetime.strptime(date_str, '%Y%m%d') - timedelta(days=31)).strftime('%Y%m%d')
        df = pro.index_weight(index_code=index_code, start_date=start_dt, end_date=date_str)
        
        # å¦‚æœæ²¡æŸ¥åˆ°ï¼Œå°è¯•å¾€å‰æ‰¾åŠå¹´ï¼ˆåº”å¯¹åŠå¹´è°ƒä»“çš„æŒ‡æ•°ï¼‰
        if df.empty:
            start_dt_long = (datetime.strptime(date_str, '%Y%m%d') - timedelta(days=180)).strftime('%Y%m%d')
            df = pro.index_weight(index_code=index_code, start_date=start_dt_long, end_date=date_str)
        
        if df.empty:
            return []
            
        # å–ç¦» target_date æœ€è¿‘çš„ä¸€å¤©
        latest_date = df['trade_date'].max()
        codes = df[df['trade_date'] == latest_date]['con_code'].unique().tolist()
        return codes

    except Exception as e:
        print(f"      [Err] è·å–æˆåˆ†è‚¡å¤±è´¥: {e}")
        return []

def process_chunk(index_name, index_code, start_date, end_date, all_stocks_set=None):
    """å¤„ç†ä¸€ä¸ªæ—¶é—´åˆ‡ç‰‡ (å­£åº¦)
    
    Args:
        index_name: æŒ‡æ•°åç§°
        index_code: æŒ‡æ•°ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        all_stocks_set: å…¨å¸‚åœºè‚¡ç¥¨é›†åˆï¼ˆç”¨äºéåˆ›ä¸šæ¿æŒ‡æ•°ï¼‰
    """
    print(f"   -> æ­£åœ¨å¤„ç†åŒºé—´: {start_date} ~ {end_date}")
    
    # 1. è·å–æˆåˆ†è‚¡ï¼šåªæœ‰åˆ›ä¸šæ¿éœ€è¦è·å–æˆåˆ†è‚¡ï¼Œå…¶ä»–ç”¨å…¨å¸‚åœº
    if index_code == '399006.SZ':  # åˆ›ä¸šæ¿
        stock_list = get_constituents_safe(index_code, start_date)
        if not stock_list:
            print(f"      [è·³è¿‡] æ— æ³•è·å–æˆåˆ†è‚¡åˆ—è¡¨")
            return pd.DataFrame()
        print(f"      åˆ›ä¸šæ¿æˆåˆ†è‚¡æ•°é‡: {len(stock_list)}")
    else:
        # å…¶ä»–æŒ‡æ•°ï¼šä½¿ç”¨å…¨å¸‚åœºè‚¡ç¥¨
        if all_stocks_set is None:
            print(f"      [è·³è¿‡] å…¨å¸‚åœºè‚¡ç¥¨é›†åˆæœªæä¾›")
            return pd.DataFrame()
        stock_list = list(all_stocks_set)
        print(f"      ä½¿ç”¨å…¨å¸‚åœºè‚¡ç¥¨æ•°é‡: {len(stock_list)}")

    # 2. æ‹‰å–æ•°æ® (å«40å¤© Buffer ç®—å‡çº¿)
    real_start_date = (datetime.strptime(start_date, '%Y%m%d') - timedelta(days=50)).strftime('%Y%m%d')
    
    all_dfs = []
    batch_size = 50 # 50åªä¸€æ‰¹ï¼Œç¨³å®šç¬¬ä¸€
    
    # è¿›åº¦æ¡æ˜¾ç¤º
    total_batches = (len(stock_list) + batch_size - 1) // batch_size
    
    for i in range(0, len(stock_list), batch_size):
        batch = stock_list[i:i+batch_size]
        codes_str = ','.join(batch)
        try:
            # è¿™é‡Œçš„ batch_start/end æ˜¯ä¸ºäº†èŠ‚çœå†…å­˜ï¼Œåªå–æˆ‘ä»¬éœ€è¦çš„æ—¶é—´æ®µ
            df_d = pro.daily(ts_code=codes_str, start_date=real_start_date, end_date=end_date)
            df_f = pro.adj_factor(ts_code=codes_str, start_date=real_start_date, end_date=end_date)
            
            if not df_d.empty and not df_f.empty:
                df_d = df_d[['ts_code', 'trade_date', 'close', 'pct_chg']]
                df_f = df_f[['ts_code', 'trade_date', 'adj_factor']]
                
                # è·å–æ¯æ—¥åŸºç¡€æ•°æ® (æ¢æ‰‹ç‡)
                # æ³¨æ„ï¼šdaily_basicæ¥å£æ‰¹é‡æŸ¥è¯¢ä¼šè¿”å›ç©ºæ•°æ®ï¼Œéœ€è¦é€ä¸ªæŸ¥è¯¢
                all_basic = []
                for code in batch:
                    try:
                        df_b = pro.daily_basic(ts_code=code, start_date=real_start_date, end_date=end_date, fields='ts_code,trade_date,turnover_rate')
                        if not df_b.empty:
                            all_basic.append(df_b)
                    except:
                        pass

                df_m = pd.merge(df_d, df_f, on=['ts_code', 'trade_date'], how='inner')
                if all_basic:
                    df_b_all = pd.concat(all_basic)
                    df_m = pd.merge(df_m, df_b_all, on=['ts_code', 'trade_date'], how='left')
                    df_m['turnover_rate'] = df_m['turnover_rate'].fillna(0)
                else:
                    df_m['turnover_rate'] = 0.0
                
                all_dfs.append(df_m)
        except:
            time.sleep(1) # æŠ¥é”™ç¨å¾®æ­‡ä¸€ä¸‹
            pass
        
        # ç®€å•é˜²æµæ§
        time.sleep(0.05)

    if not all_dfs: 
        return pd.DataFrame()
    
    # 3. åˆå¹¶ä¸è®¡ç®—
    df_all = pd.concat(all_dfs, ignore_index=True)
    df_all = df_all.sort_values(['ts_code', 'trade_date'])
    
    # è®¡ç®—å¤æƒä»·
    df_all['hfq_close'] = df_all['close'] * df_all['adj_factor']
    
    # è®¡ç®— MA20
    df_all['ma20'] = df_all.groupby('ts_code')['hfq_close'].transform(lambda x: x.rolling(20).mean())
    df_all['is_above_ma20'] = (df_all['hfq_close'] > df_all['ma20']).astype(int)
    
    # è®¡ç®— è¿è·Œ3æ—¥ (ä½¿ç”¨ pct_chg)
    df_all['is_down'] = (df_all['pct_chg'] < 0)
    # shift(1)æ˜¯æ˜¨å¤©
    df_all['down_1'] = df_all.groupby('ts_code')['is_down'].shift(1)
    df_all['down_2'] = df_all.groupby('ts_code')['is_down'].shift(2)
    df_all['is_down_3days'] = (df_all['is_down'] & df_all['down_1'] & df_all['down_2']).astype(int)
    
    # Calculate turnover status
    df_all['is_turnover_lt_3'] = (df_all['turnover_rate'] < 3.0).astype(int)
    df_all['is_turnover_gt_5'] = (df_all['turnover_rate'] > 5.0).astype(int)
    
    # 4. æˆªå–æœ‰æ•ˆæ—¶é—´æ®µ (å»æ‰Buffer)
    df_valid = df_all[df_all['trade_date'] >= start_date].copy()
    
    # 5. èšåˆç»Ÿè®¡
    df_stats = df_valid.groupby('trade_date').agg(
        total_count=('ts_code', 'count'),
        ma20_count=('is_above_ma20', 'sum'),
        down3_count=('is_down_3days', 'sum'),
        turnover_lt_3_count=('is_turnover_lt_3', 'sum'),
        turnover_gt_5_count=('is_turnover_gt_5', 'sum')
    ).reset_index()
    
    return df_stats

def calculate_crowd_index(pro, trade_date):
    """è®¡ç®—çœŸå®çš„æ‹¥æŒ¤åº¦æŒ‡æ ‡ï¼šæˆäº¤é¢æ’åå‰5%çš„ä¸ªè‚¡æˆäº¤é¢å å…¨éƒ¨Aæˆäº¤é¢çš„æ¯”ä¾‹"""
    try:
        # è·å–å…¨éƒ¨Aè‚¡çš„æˆäº¤é¢æ•°æ®
        df_daily = pro.daily(trade_date=trade_date, fields='ts_code,amount')
        if df_daily.empty:
            return 0
        
        # è®¡ç®—æˆäº¤é¢å‰5%çš„ä¸ªè‚¡
        total_stocks = len(df_daily)
        top_5_pct_count = max(1, int(total_stocks * 0.05))  # è‡³å°‘1åª
        
        # æŒ‰æˆäº¤é¢é™åºæ’åº
        df_sorted = df_daily.sort_values('amount', ascending=False)
        
        # è·å–å‰5%çš„ä¸ªè‚¡
        top_5_pct = df_sorted.head(top_5_pct_count)
        
        # è®¡ç®—å‰5%æˆäº¤é¢æ€»å’Œ
        top_5_pct_amount = top_5_pct['amount'].sum()
        
        # è®¡ç®—å…¨éƒ¨Aè‚¡æˆäº¤é¢æ€»å’Œ
        total_amount = df_daily['amount'].sum()
        
        # è®¡ç®—æ‹¥æŒ¤åº¦
        if total_amount > 0:
            crowd_index = (top_5_pct_amount / total_amount) * 100
            return round(crowd_index, 2)
        else:
            return 0
    except Exception as e:
        print(f"è®¡ç®—æ‹¥æŒ¤åº¦å¼‚å¸¸ ({trade_date}): {e}")
        return 0

def run_full_backfill():
    # === é…ç½®åŒºåŸŸ ===
    # ä¸´æ—¶ä¿®æ”¹ï¼šåªå›å¡«æœ€è¿‘3ä¸ªæœˆæ•°æ®ï¼ˆéªŒè¯ä¿®å¤æ•ˆæœï¼‰
    from datetime import datetime, timedelta
    START_DATE = (datetime.now() - timedelta(days=90)).strftime('%Y%m%d')  # æœ€è¿‘3ä¸ªæœˆ
    END_DATE   = datetime.now().strftime('%Y%m%d')
    # å…¨é‡å›å¡«æ—¶ä½¿ç”¨: START_DATE = '20190101'
    # =============

    print(f" å¯åŠ¨å›å¡«ä»»åŠ¡: {START_DATE} ~ {END_DATE} (æœ€è¿‘3ä¸ªæœˆéªŒè¯)")
    
    conn = sqlite3.connect(DB_PATH)
    intervals = get_quarters(START_DATE, END_DATE)
    
    # è·å–å…¨å¸‚åœºAè‚¡è‚¡ç¥¨åˆ—è¡¨ï¼ˆç”¨äºéåˆ›ä¸šæ¿æŒ‡æ•°ï¼‰
    print(f"\n====== è·å–å…¨å¸‚åœºAè‚¡åˆ—è¡¨ ======")
    try:
        df_all_stocks = pro.stock_basic(exchange='', list_status='L', fields='ts_code')
        all_stocks_set = set(df_all_stocks['ts_code'].tolist())
        print(f"   -> å…¨å¸‚åœºAè‚¡æ•°é‡: {len(all_stocks_set)}")
    except Exception as e:
        print(f"   [Error] è·å–å…¨å¸‚åœºè‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        all_stocks_set = set()
    
    # å…ˆè·å–æ‰€æœ‰éœ€è¦è®¡ç®—æ‹¥æŒ¤åº¦çš„æ—¥æœŸ
    all_dates = []
    for (s_date, e_date) in intervals:
        try:
            df_cal = pro.trade_cal(exchange='SSE', is_open='1', start_date=s_date, end_date=e_date)
            all_dates.extend(df_cal['cal_date'].values)
        except:
            pass
    
    # å»é‡å¹¶æ’åº
    all_dates = sorted(list(set(all_dates)))
    
    # å…ˆè®¡ç®—æ‰€æœ‰æ—¥æœŸçš„æ‹¥æŒ¤åº¦ï¼Œå­˜å‚¨åˆ°å­—å…¸ä¸­ï¼Œé¿å…é‡å¤è®¡ç®—
    crowd_index_dict = {}
    print(f"\n====== è®¡ç®—æ‰€æœ‰æ—¥æœŸçš„æ‹¥æŒ¤åº¦ ======")
    for i, trade_date in enumerate(all_dates):
        if i % 10 == 0:  # æ¯10å¤©æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            print(f"   è®¡ç®—æ‹¥æŒ¤åº¦: {i+1}/{len(all_dates)} - {trade_date}")
        crowd_index = calculate_crowd_index(pro, trade_date)
        crowd_index_dict[trade_date] = crowd_index
    
    for index_name, index_code in INDEX_MAP.items():
        print(f"\n====== å¤„ç†æŒ‡æ•°: {index_name} ======")
        
        # 1. è·å–æŒ‡æ•°è‡ªèº«ä»·æ ¼ (ç”¨æ¥åšä¸»å›¾)
        try:
            print("   -> æ‹‰å–æŒ‡æ•°è¡Œæƒ…...")
            # ç‰¹æ®Šå¤„ç†ä¸­è¯2000æŒ‡æ•°
            if index_code == '932000.CSI':
                # ä¸­è¯2000æŒ‡æ•°å¯èƒ½æ²¡æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®ï¼Œå°è¯•è·å–å®ƒå®é™…å­˜åœ¨çš„æ—¶é—´èŒƒå›´
                print(f"   -> ç‰¹æ®Šå¤„ç† {index_name} æŒ‡æ•°...")
                # å…ˆå°è¯•è·å–æœ€æ–°æ•°æ®ï¼Œç¡®å®šè¯¥æŒ‡æ•°æ˜¯å¦å­˜åœ¨
                df_latest = pro.index_daily(ts_code=index_code, start_date='20200101', end_date=END_DATE, limit=1)
                if df_latest.empty:
                    print(f"   [Skip] {index_name} æŒ‡æ•°æ•°æ®ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†")
                    continue
                # å¦‚æœå­˜åœ¨ï¼Œåªè·å–å®ƒå®é™…å­˜åœ¨çš„æ—¶é—´èŒƒå›´
                df_idx_price = pro.index_daily(ts_code=index_code, start_date='20200101', end_date=END_DATE)
                if df_idx_price.empty:
                    print(f"   [Skip] {index_name} æŒ‡æ•°æ— è¡Œæƒ…æ•°æ®ï¼Œè·³è¿‡å¤„ç†")
                    continue
            else:
                # å…¶ä»–æŒ‡æ•°æ­£å¸¸å¤„ç†
                df_idx_price = pro.index_daily(ts_code=index_code, start_date=START_DATE, end_date=END_DATE)
            
            df_idx_price = df_idx_price[['trade_date', 'close']].rename(columns={'close': 'idx_close'})
            print(f"   -> æˆåŠŸè·å– {len(df_idx_price)} æ¡æŒ‡æ•°è¡Œæƒ…æ•°æ®")
        except Exception as e:
            print(f"   [Error] æŒ‡æ•°è¡Œæƒ…æ‹‰å–å¤±è´¥: {e}")
            continue

        # 2. æŒ‰å­£åº¦å¾ªç¯å¤„ç†
        for (s_date, e_date) in intervals:
            try:
                df_breadth = process_chunk(index_name, index_code, s_date, e_date, all_stocks_set)
                
                if not df_breadth.empty:
                    # åˆå¹¶æŒ‡æ•°ä»·æ ¼
                    df_final = pd.merge(df_breadth, df_idx_price, on='trade_date', how='inner')
                    
                    # ç®—ç™¾åˆ†æ¯”
                    df_final['pct_above_ma20'] = (df_final['ma20_count'] / df_final['total_count']) * 100
                    df_final['pct_down_3days'] = (df_final['down3_count'] / df_final['total_count']) * 100
                    df_final['pct_turnover_lt_3'] = (df_final['turnover_lt_3_count'] / df_final['total_count']) * 100
                    df_final['pct_turnover_gt_5'] = (df_final['turnover_gt_5_count'] / df_final['total_count']) * 100
                    
                    # å…¥åº“
                    data_tuples = []
                    for _, row in df_final.iterrows():
                        trade_date = row['trade_date']
                        # è·å–é¢„å…ˆè®¡ç®—å¥½çš„æ‹¥æŒ¤åº¦ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¸º0.0
                        crowd_index = crowd_index_dict.get(trade_date, 0.0)
                        data_tuples.append((
                            trade_date, index_code, index_name,
                            row['idx_close'], row['pct_above_ma20'], row['pct_down_3days'], crowd_index,
                            row['pct_turnover_lt_3'], row['pct_turnover_gt_5']
                        ))
                    
                    c = conn.cursor()
                    c.executemany('INSERT OR REPLACE INTO market_breadth VALUES (?,?,?,?,?,?,?,?,?)', data_tuples)
                    conn.commit()
                    print(f"      [âˆš] å·²å…¥åº“ {len(df_final)} å¤©æ•°æ®")
                
            except Exception as e:
                print(f"      [!!!] åŒºé—´å¤„ç†å¼‚å¸¸: {e}")
                time.sleep(5) # å‡ºé”™å¤šæ­‡ä¼š

    conn.close()
    print("\nğŸ‰ å…¨é‡å†å²å›å¡«å®Œæˆï¼")

if __name__ == "__main__":
    run_full_backfill()